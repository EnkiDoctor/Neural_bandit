{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import math \n",
    "import copy\n",
    "import random\n",
    "import argparse\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义一个简单的神经网络模型\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        # 使用Xavier初始化来初始化权重\n",
    "        nn.init.xavier_normal_(self.fc1.weight)\n",
    "        nn.init.xavier_normal_(self.fc2.weight)\n",
    "\n",
    "        # 初始化偏置为零\n",
    "        nn.init.constant_(self.fc1.bias, 0)\n",
    "        nn.init.constant_(self.fc2.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.fc4(out)\n",
    "        out = self.relu4(out)\n",
    "        return out\n",
    "        \n",
    "# 定义输入、隐藏层和输出的维度\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "output_size = 10\n",
    "\n",
    "# 创建一个SimpleNN模型\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customloss(nn.Module):\n",
    "    def __init__(self, theta):\n",
    "        super(customloss, self).__init__()\n",
    "        self.theta = theta\n",
    "    def forward(self, output_list, y_list):\n",
    "        theta = torch.tensor(self.theta, dtype= torch.float32).to(device) \n",
    "        loss = 0\n",
    "        index = 0\n",
    "        for output in output_list:  \n",
    "            y = torch.tensor(y_list[index]).to(device) \n",
    "            v = torch.mm(output, theta.view(-1,1)) \n",
    "            prob = torch.exp(v) / (torch.sum(torch.exp(v)))  \n",
    "            loss += torch.sum(-y * torch.log(prob) - (1-y) * torch.log(1-prob)) \n",
    "            index += 1  \n",
    "        return loss / (len(y_list)/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_ARRAY = np.load('features1.npy')\n",
    "theta = np.load('theta.npy')\n",
    "PURCHASE_LIST = np.load('purchase.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 2411.39892578125\n",
      "epoch 0, loss 2411.3798828125\n",
      "epoch 0, loss 2411.36767578125\n",
      "epoch 0, loss 2411.357421875\n",
      "epoch 0, loss 2411.349853515625\n",
      "epoch 0, loss 2411.34375\n",
      "epoch 0, loss 2411.34033203125\n",
      "epoch 0, loss 2411.337158203125\n",
      "epoch 0, loss 2411.334716796875\n",
      "epoch 0, loss 2411.333251953125\n",
      "epoch 0, loss 2411.332275390625\n",
      "epoch 0, loss 2411.33154296875\n",
      "epoch 0, loss 2411.330810546875\n",
      "epoch 0, loss 2411.33056640625\n",
      "epoch 0, loss 2411.330078125\n",
      "epoch 0, loss 2411.329833984375\n",
      "epoch 0, loss 2411.32958984375\n",
      "epoch 0, loss 2411.329345703125\n",
      "epoch 0, loss 2411.329345703125\n",
      "epoch 0, loss 2411.3291015625\n",
      "epoch 0, loss 2411.3291015625\n",
      "epoch 0, loss 2411.3291015625\n",
      "epoch 0, loss 2411.3291015625\n",
      "epoch 0, loss 2411.328857421875\n",
      "epoch 0, loss 2411.32861328125\n",
      "epoch 0, loss 2411.328857421875\n",
      "epoch 0, loss 2411.32861328125\n",
      "epoch 0, loss 2411.34033203125\n",
      "epoch 0, loss 2411.353271484375\n",
      "epoch 0, loss 2411.365478515625\n",
      "epoch 0, loss 2411.376708984375\n",
      "epoch 0, loss 2411.387451171875\n",
      "epoch 0, loss 2411.3974609375\n",
      "epoch 0, loss 2411.40673828125\n",
      "epoch 0, loss 2411.41552734375\n",
      "epoch 0, loss 2411.424072265625\n",
      "epoch 0, loss 2411.43212890625\n",
      "epoch 0, loss 2411.439453125\n",
      "epoch 0, loss 2411.44677734375\n",
      "epoch 0, loss 2411.45361328125\n",
      "epoch 0, loss 2411.4599609375\n",
      "epoch 0, loss 2411.46630859375\n",
      "epoch 0, loss 2411.471923828125\n",
      "epoch 0, loss 2411.477783203125\n",
      "epoch 0, loss 2411.483154296875\n",
      "epoch 0, loss 2411.488037109375\n",
      "epoch 0, loss 2411.492919921875\n",
      "epoch 0, loss 2411.497802734375\n",
      "epoch 0, loss 2411.502197265625\n",
      "epoch 0, loss 2411.506591796875\n",
      "epoch 0, loss 2411.5107421875\n",
      "epoch 0, loss 2411.514892578125\n",
      "epoch 0, loss 2411.5185546875\n",
      "epoch 0, loss 2411.522216796875\n",
      "epoch 0, loss 2411.5166015625\n",
      "epoch 0, loss 2411.506591796875\n",
      "epoch 0, loss 2411.496337890625\n",
      "epoch 0, loss 2411.48681640625\n",
      "epoch 0, loss 2411.4775390625\n",
      "epoch 0, loss 2411.468505859375\n",
      "epoch 0, loss 2411.459716796875\n",
      "epoch 0, loss 2411.451171875\n",
      "epoch 0, loss 2411.443359375\n",
      "epoch 0, loss 2411.435302734375\n",
      "epoch 0, loss 2411.427734375\n",
      "epoch 0, loss 2411.42041015625\n",
      "epoch 0, loss 2411.412841796875\n",
      "epoch 0, loss 2411.406005859375\n",
      "epoch 0, loss 2411.399169921875\n",
      "epoch 0, loss 2411.392578125\n",
      "epoch 0, loss 2411.38623046875\n",
      "epoch 0, loss 2411.380126953125\n",
      "epoch 0, loss 2411.3740234375\n",
      "epoch 0, loss 2411.3681640625\n",
      "epoch 0, loss 2411.3623046875\n",
      "epoch 0, loss 2411.356689453125\n",
      "epoch 0, loss 2411.351318359375\n",
      "epoch 0, loss 2411.345947265625\n",
      "epoch 0, loss 2411.3408203125\n",
      "epoch 0, loss 2411.335693359375\n",
      "epoch 0, loss 2411.330810546875\n",
      "epoch 0, loss 2411.325927734375\n",
      "epoch 0, loss 2411.3212890625\n",
      "epoch 0, loss 2411.31689453125\n",
      "epoch 0, loss 2411.312255859375\n",
      "epoch 0, loss 2411.307861328125\n",
      "epoch 0, loss 2411.3037109375\n",
      "epoch 0, loss 2411.299560546875\n",
      "epoch 0, loss 2411.29541015625\n",
      "epoch 0, loss 2411.29150390625\n",
      "epoch 0, loss 2411.28759765625\n",
      "epoch 0, loss 2411.283935546875\n",
      "epoch 0, loss 2411.280029296875\n",
      "epoch 0, loss 2411.2763671875\n",
      "epoch 0, loss 2411.27294921875\n",
      "epoch 0, loss 2411.26953125\n",
      "epoch 0, loss 2411.265869140625\n",
      "epoch 0, loss 2411.262451171875\n",
      "epoch 0, loss 2411.25927734375\n",
      "epoch 0, loss 2411.256103515625\n"
     ]
    }
   ],
   "source": [
    "feature_list = []\n",
    "purchase_list = []\n",
    "\n",
    "model = SimpleNN(input_size, hidden_size, output_size).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=0.01)\n",
    "for t in range(0,10000):\n",
    "    context = CONTEXT_ARRAY[t]\n",
    "\n",
    "    purchase_list.append(PURCHASE_LIST[t])\n",
    "\n",
    "    feature_list.append(np.array(context))\n",
    "\n",
    "    if t%100 == 99:\n",
    "        loss_function = customloss(theta)\n",
    "        epochs = 1\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            output_list = [model(torch.tensor(a,dtype = torch.float32).to(device)) for a in feature_list]\n",
    "            loss = loss_function(output_list, purchase_list)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "         \n",
    "            print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07958204 0.22451541 0.24934586 0.08885355 0.05108825 0.08780105\n",
      " 0.09688146 0.12193237]\n",
      "[[0.12506875 0.12487867 0.12472919 0.12538411 0.12547892 0.1245039\n",
      "  0.12506193 0.12489452]]\n"
     ]
    }
   ],
   "source": [
    "problist  = np.load('prob_list.npy')\n",
    "def hhh(i):\n",
    "    ff = model(torch.tensor(CONTEXT_ARRAY[i],dtype = torch.float32).to(device))\n",
    "    ff = ff.cpu().detach().numpy()\n",
    "    u = (ff @ theta.T ).reshape(1,-1)\n",
    "    prob = np.exp(u) / (np.sum(np.exp(u)))\n",
    "    \n",
    "    print(problist[i])\n",
    "    print(prob)\n",
    "\n",
    "hhh(100)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "\n",
    "    def forward(self, output_list, y_list, theta):\n",
    "        theta = torch.tensor(theta, dtype=torch.float32).to(output_list[0].device)\n",
    "        loss = 0\n",
    "        for output, y in zip(output_list, y_list):\n",
    "            v = torch.matmul(output, theta)\n",
    "            prob = torch.exp(v) / torch.sum(torch.exp(v))\n",
    "            loss += torch.sum(-y * torch.log(prob) - (1-y) * torch.log(1-prob))\n",
    "        return loss / len(y_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bandit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
