{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import math \n",
    "import copy\n",
    "import random\n",
    "import argparse\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import modeldefine\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "\n",
    "def UCB(A, phi):\n",
    "    #### ucb term\n",
    "    phi = phi.view(-1,1)\n",
    "    try:\n",
    "        tmp, LU = torch.linalg.solve(phi,A)\n",
    "    except:\n",
    "        A = A.detach().numpy()\n",
    "        phi2 = phi.detach().numpy()\n",
    "        tmp = torch.Tensor(np.linalg.solve(A, phi2))\n",
    "\n",
    "    return torch.sqrt(torch.matmul(torch.transpose(phi,1,0), tmp))\n",
    "\n",
    "def calculate_v(contextinfo_list, A, theta):\n",
    "    vj_list = []\n",
    "    feature_list = []\n",
    "    for i in contextinfo_list:\n",
    "        feature = model(i.to(device)).cpu()\n",
    "        first_item =  torch.mm( feature.view(1,-1) , theta)\n",
    "        second_item = alpha * UCB(A, feature)\n",
    "        vj_list.append((first_item + second_item).item())\n",
    "        feature_list.append(feature.detach().numpy())\n",
    "    return np.array(vj_list), feature_list\n",
    "\n",
    "def update_A(A, info_subset):\n",
    "    for i in info_subset:\n",
    "        i = torch.tensor(i, dtype=torch.float32,device=device)\n",
    "        feature = model(i.to(device)).view(1,-1).cpu()\n",
    "        A = A + torch.mm(feature.t(), feature)\n",
    "    return A\n",
    "\n",
    "def prob(vj_list):\n",
    "    sum = np.sum(np.exp(vj_list)) + 1\n",
    "    return [np.exp(vj_list[i]) / sum for i in range(len(vj_list))]  \n",
    "\n",
    "def revenue(vj_list, reward_list):\n",
    "    sum = np.sum(np.exp(vj_list)) + 1\n",
    "    return np.sum(np.multiply(np.exp(vj_list), reward_list) / sum)\n",
    "\n",
    "def assort(contextinfo_list, reward_list, vj_list):\n",
    "    length = len(vj_list)\n",
    "    # sort the contextinfo_list and vj with descending order of reward_list\n",
    "    sorted_list = sorted(zip(contextinfo_list, vj_list, reward_list), key=lambda x: x[2], reverse=True)\n",
    "    contextinfo_list = [x[0] for x in sorted_list]\n",
    "    vj_list = [x[1] for x in sorted_list]\n",
    "    reward_list = [x[2] for x in sorted_list]\n",
    "\n",
    "    # calculate the optimal assortment\n",
    "    optimal_assort = []\n",
    "    optimal_reward = 0\n",
    "    index = 1\n",
    "    for i in range(length):\n",
    "        if revenue(vj_list[:index], reward_list[:index]) >= optimal_reward:\n",
    "            optimal_reward = revenue(vj_list[:index], reward_list[:index])\n",
    "            index += 1\n",
    "        else:\n",
    "            break\n",
    "    return contextinfo_list[:index]\n",
    "\n",
    "# this is for the linear purchase model when v = x dot theta\n",
    "def get_linear_purchase(feature_list):\n",
    "    true_Vlist = [(TRUE_THETA @ feature_list[i].reshape(-1,1)).item() for  i in range(len(feature_list))]\n",
    "    prob_list = prob(true_Vlist)\n",
    "\n",
    "    # sample item according to prob_list\n",
    "    if random.uniform(0,1) < 1 - np.sum(prob_list):\n",
    "        return np.array([0 for i in range(len(feature_list))])\n",
    "    else:\n",
    "        returnlist = [0 for i in range(len(feature_list))]\n",
    "        indexchoose = random.choices([i for i in range(len(prob_list))], weights = prob_list)[0]\n",
    "        returnlist[indexchoose] = 1\n",
    "        return np.array(returnlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(theta, feature_list ,y_list):\n",
    "    # feature's dimension is len * dimension , theta is 1*dimension\n",
    "    v_list = np.matmul(feature_list, theta.T).reshape(-1)\n",
    "    ln_prob = np.log(prob(v_list))\n",
    "    summation = ln_prob * y_list\n",
    "    return -1 * np.sum(summation)\n",
    "\n",
    "def likelihood_derivative(theta, feature_list, y_list):\n",
    "    v_list = np.matmul(feature_list, theta.T).reshape(-1)\n",
    "    prob_list = prob(v_list)\n",
    "    summation = np.matmul(np.array(feature_list).T, (y_list - prob_list))\n",
    "    return -1 * summation\n",
    "\n",
    "def likelihood_array(theta, feature_list_list, y_list_list):\n",
    "    summation = 0\n",
    "    for i in range(len(feature_list_list)):\n",
    "        summation += likelihood(theta, feature_list_list[i], y_list_list[i])\n",
    "    return summation\n",
    "\n",
    "def likelihood_derivative_array(theta, feature_list_list, y_list_list):\n",
    "    summation = 0\n",
    "    for i in range(len(feature_list_list)):\n",
    "        summation += likelihood_derivative(theta, feature_list_list[i], y_list_list[i])\n",
    "    return summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最优参数: [ 0.20200196  1.09390141 -0.2223418   1.2732161   0.00643495  0.71511672\n",
      "  0.36041456  0.4408483   0.12065533  1.37386217]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "initial_guess = np.array([0.5 for i in range(10)])  \n",
    "\n",
    "known_feature = ass_list\n",
    "known_y =  purchase_list\n",
    "\n",
    "result = minimize(likelihood_array, initial_guess, args=(known_feature, known_y), method='SLSQP', \n",
    "                  constraints={'type':'eq', 'fun': likelihood_derivative_array, 'args':(known_feature, known_y)})\n",
    "\n",
    "optimal_parameters = result.x\n",
    "print(\"最优参数:\", optimal_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLikelihoodLoss(nn.Module):\n",
    "    def __init__(self, theta_list):\n",
    "        super(CustomLikelihoodLoss, self).__init__()\n",
    "        self.theta_list = theta_list\n",
    "        \n",
    "    def forward(self, output_list, y_list):\n",
    "        loss = 0\n",
    "        index = 0\n",
    "        for output in output_list:  \n",
    "            y = torch.tensor(y_list[index]).to(device)\n",
    "            theta = torch.tensor(self.theta_list[index], dtype= torch.float32).to(device)\n",
    "            v = torch.mm(output, theta.view(-1,1))\n",
    "            prob = torch.exp(v) / (torch.sum(torch.exp(v)) + 1)\n",
    "            loss += torch.sum(torch.log(prob) * y)\n",
    "            index += 1  \n",
    "        return -loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a test set \n",
    "a = torch.randn(100,10).numpy()\n",
    "y = np.array([1] + [0 for i in range(99)])\n",
    "y = np.random.permutation(y)\n",
    "\n",
    "a_list = []\n",
    "y_list = []\n",
    "theta_list = []\n",
    "\n",
    "for i in [20,30,50,100, 60, 80]:\n",
    "    a = torch.randn(i,10).numpy()\n",
    "    a_list.append(a)\n",
    "    y = np.array([1] + [0 for i in range(i-1)]) \n",
    "    y = np.random.permutation(y)\n",
    "    y_list.append(y) \n",
    "    theta_list.append(np.random.randn(10).reshape(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5, 10, 10, 10, 10, 10, 10], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import modeldefine\n",
    "import torch.optim as optim\n",
    "model = modeldefine.Model(5,10,10,5).to(device)\n",
    "# 10 20 20 20 20 20  5\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1420.2215576171875\n",
      "Epoch [2/10], Loss: 1420.221435546875\n",
      "Epoch [3/10], Loss: 1420.221435546875\n",
      "Epoch [4/10], Loss: 1420.221435546875\n",
      "Epoch [5/10], Loss: 1420.221435546875\n",
      "Epoch [6/10], Loss: 1420.221435546875\n",
      "Epoch [7/10], Loss: 1420.221435546875\n",
      "Epoch [8/10], Loss: 1420.221435546875\n",
      "Epoch [9/10], Loss: 1420.2213134765625\n",
      "Epoch [10/10], Loss: 1420.221435546875\n"
     ]
    }
   ],
   "source": [
    "loss_function = CustomLikelihoodLoss(theta_list)\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    output_list = [model(torch.tensor(a).to(device)) for a in a_list]\n",
    "    loss = loss_function(output_list, y_list)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}\")\n",
    "      \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_ARRAY = np.load('linear_data/features.npy') \n",
    "REWARD_ARRAY = np.load('linear_data/rewards.npy')\n",
    "TRUE_THETA = np.load('linear_data/theta.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter [ -3.65485869  -0.27586319 -18.13971029  -0.1058296   22.44320769\n",
      " -12.62487191 -12.27172787  28.08716113  11.06667852 -16.77196907]\n",
      "best parameter [ -5.25541801 -19.48799165 -19.29572754 -20.69272402  39.46759166\n",
      " -26.14380356 -19.75495139  45.86542572  12.03243517 -17.77998203]\n",
      "best parameter [ 221.35084887  105.1610079   313.09390291 -108.46434962 -495.96326589\n",
      "  169.13720531  382.34201289 -297.41264449 -437.77185336  491.25441402]\n",
      "best parameter [ 221.35084887  105.1610079   313.09390291 -108.46434962 -495.96326589\n",
      "  169.13720531  382.34201289 -297.41264449 -437.77185336  491.25441402]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\杜骏晔\\AppData\\Local\\Temp\\ipykernel_22676\\3307443883.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  ln_prob = np.log(prob(v_list))\n",
      "C:\\Users\\杜骏晔\\AppData\\Local\\Temp\\ipykernel_22676\\3307443883.py:5: RuntimeWarning: invalid value encountered in multiply\n",
      "  summation = ln_prob * y_list\n",
      "C:\\Users\\杜骏晔\\AppData\\Local\\Temp\\ipykernel_22676\\263305036.py:34: RuntimeWarning: overflow encountered in exp\n",
      "  sum = np.sum(np.exp(vj_list)) + 1\n",
      "C:\\Users\\杜骏晔\\AppData\\Local\\Temp\\ipykernel_22676\\263305036.py:35: RuntimeWarning: overflow encountered in exp\n",
      "  return [np.exp(vj_list[i]) / sum for i in range(len(vj_list))]\n",
      "C:\\Users\\杜骏晔\\AppData\\Local\\Temp\\ipykernel_22676\\263305036.py:35: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return [np.exp(vj_list[i]) / sum for i in range(len(vj_list))]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter [nan nan nan nan nan nan nan nan nan nan]\n",
      "best parameter [nan nan nan nan nan nan nan nan nan nan]\n",
      "best parameter [nan nan nan nan nan nan nan nan nan nan]\n",
      "best parameter [nan nan nan nan nan nan nan nan nan nan]\n",
      "best parameter [nan nan nan nan nan nan nan nan nan nan]\n",
      "best parameter [nan nan nan nan nan nan nan nan nan nan]\n",
      "best parameter [nan nan nan nan nan nan nan nan nan nan]\n",
      "best parameter [nan nan nan nan nan nan nan nan nan nan]\n",
      "best parameter [nan nan nan nan nan nan nan nan nan nan]\n",
      "best parameter [nan nan nan nan nan nan nan nan nan nan]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\gitproject\\Neural_bandit\\neural_ass\\asstest.ipynb Cell 12\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/gitproject/Neural_bandit/neural_ass/asstest.ipynb#X14sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# update theta using MLE\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/gitproject/Neural_bandit/neural_ass/asstest.ipynb#X14sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m initial_guess \u001b[39m=\u001b[39m theta\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/gitproject/Neural_bandit/neural_ass/asstest.ipynb#X14sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m result \u001b[39m=\u001b[39m minimize(likelihood_array, initial_guess, args\u001b[39m=\u001b[39;49m(ass_list, purchase_list), method\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mSLSQP\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/gitproject/Neural_bandit/neural_ass/asstest.ipynb#X14sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m               constraints\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mtype\u001b[39;49m\u001b[39m'\u001b[39;49m:\u001b[39m'\u001b[39;49m\u001b[39meq\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mfun\u001b[39;49m\u001b[39m'\u001b[39;49m: likelihood_derivative_array, \u001b[39m'\u001b[39;49m\u001b[39margs\u001b[39;49m\u001b[39m'\u001b[39;49m:(ass_list, purchase_list)})\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/gitproject/Neural_bandit/neural_ass/asstest.ipynb#X14sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m theta \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mx\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/gitproject/Neural_bandit/neural_ass/asstest.ipynb#X14sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mbest parameter\u001b[39m\u001b[39m\"\u001b[39m,theta)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\bandit\\lib\\site-packages\\scipy\\optimize\\_minimize.py:719\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    716\u001b[0m     res \u001b[39m=\u001b[39m _minimize_cobyla(fun, x0, args, constraints, callback\u001b[39m=\u001b[39mcallback,\n\u001b[0;32m    717\u001b[0m                            bounds\u001b[39m=\u001b[39mbounds, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[0;32m    718\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mslsqp\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 719\u001b[0m     res \u001b[39m=\u001b[39m _minimize_slsqp(fun, x0, args, jac, bounds,\n\u001b[0;32m    720\u001b[0m                           constraints, callback\u001b[39m=\u001b[39mcallback, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[0;32m    721\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrust-constr\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    722\u001b[0m     res \u001b[39m=\u001b[39m _minimize_trustregion_constr(fun, x0, args, jac, hess, hessp,\n\u001b[0;32m    723\u001b[0m                                        bounds, constraints,\n\u001b[0;32m    724\u001b[0m                                        callback\u001b[39m=\u001b[39mcallback, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\bandit\\lib\\site-packages\\scipy\\optimize\\_slsqp_py.py:429\u001b[0m, in \u001b[0;36m_minimize_slsqp\u001b[1;34m(func, x0, args, jac, bounds, constraints, maxiter, ftol, iprint, disp, eps, callback, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:  \u001b[39m# objective and constraint evaluation required\u001b[39;00m\n\u001b[0;32m    428\u001b[0m     fx \u001b[39m=\u001b[39m wrapped_fun(x)\n\u001b[1;32m--> 429\u001b[0m     c \u001b[39m=\u001b[39m _eval_constraint(x, cons)\n\u001b[0;32m    431\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:  \u001b[39m# gradient evaluation required\u001b[39;00m\n\u001b[0;32m    432\u001b[0m     g \u001b[39m=\u001b[39m append(wrapped_grad(x), \u001b[39m0.0\u001b[39m)\n",
      "File \u001b[1;32md:\\anaconda\\envs\\bandit\\lib\\site-packages\\scipy\\optimize\\_slsqp_py.py:479\u001b[0m, in \u001b[0;36m_eval_constraint\u001b[1;34m(x, cons)\u001b[0m\n\u001b[0;32m    476\u001b[0m     c_ieq \u001b[39m=\u001b[39m zeros(\u001b[39m0\u001b[39m)\n\u001b[0;32m    478\u001b[0m \u001b[39m# Now combine c_eq and c_ieq into a single matrix\u001b[39;00m\n\u001b[1;32m--> 479\u001b[0m c \u001b[39m=\u001b[39m concatenate((c_eq, c_ieq))\n\u001b[0;32m    480\u001b[0m \u001b[39mreturn\u001b[39;00m c\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_length = len(CONTEXT_ARRAY)\n",
    "\n",
    "# define the hyperparameters\n",
    "input_size = 20\n",
    "hidden_size = 20\n",
    "output_size = 10\n",
    "num_layers = 10\n",
    "\n",
    "beta = 0.1\n",
    "lambd = 1\n",
    "H = 100\n",
    "\n",
    "# initialize the parameters\n",
    "\n",
    "theta = np.random.randn(output_size) / np.sqrt(output_size)\n",
    "\n",
    "LAMBDA = lambd * torch.eye(output_size, dtype=torch.float32)\n",
    "\n",
    "\n",
    "ass_list = []\n",
    "purchase_list = []\n",
    "theta_list = []\n",
    "for t in range(0,1000):\n",
    "    context = CONTEXT_ARRAY[t]\n",
    "    profit = REWARD_ARRAY[t]\n",
    "\n",
    "    theta_tensor = torch.tensor(theta.reshape(-1,1), dtype=torch.float32)\n",
    "    v_array = calculate_v(torch.tensor(context,dtype=torch.float32), LAMBDA, theta_tensor)[0]\n",
    "    assortment = assort(context, profit.tolist()[0], v_array.tolist() )\n",
    "    purchase_vector = get_linear_purchase(assortment)\n",
    "\n",
    "    ass_list.append(np.array(assortment))\n",
    "    purchase_list.append(purchase_vector)\n",
    "    # update the parameters\n",
    "    LAMBDA = update_A(LAMBDA, assortment)\n",
    "    \n",
    "    # update theta using MLE\n",
    "    \n",
    "    initial_guess = theta.reshape(-1)\n",
    "    result = minimize(likelihood_array, initial_guess, args=(ass_list, purchase_list), method='SLSQP', \n",
    "                  constraints={'type':'eq', 'fun': likelihood_derivative_array, 'args':(ass_list, purchase_list)})\n",
    "    theta = result.x\n",
    "    print(\"best parameter\",theta)\n",
    "    theta_list.append(theta)\n",
    "\n",
    "    # update the neural networks\n",
    "\n",
    "    if t % H == 99:\n",
    "        a_list = ass_list[-1*H:]\n",
    "        y_list = purchase_list[-1*H:]\n",
    "\n",
    "        loss_function = CustomLikelihoodLoss(theta_list)\n",
    "        epochs = 10\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            output_list = [model(torch.tensor(a).to(device)) for a in a_list]\n",
    "            loss = loss_function(output_list, y_list)\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}\")\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        theta_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05134156,  0.44189152, -0.36538186, -0.57603799,  0.06984549,\n",
       "       -0.1480748 , -0.66388569,  0.0571648 ,  0.25735109, -0.21071689])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.36742174,  0.0936108 ,  0.57270489, -0.03360713,  0.12895855,\n",
       "        0.36702502, -0.24374787, -0.61300754,  0.06826002,  0.1770414 ])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn(output_size) / np.sqrt(output_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bandit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
