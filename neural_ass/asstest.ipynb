{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import math \n",
    "import copy\n",
    "import random\n",
    "import argparse\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import modeldefine\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "\n",
    "def UCB(A, phi):\n",
    "    #### ucb term\n",
    "    phi = phi.view(-1,1)\n",
    "    try:\n",
    "        tmp, LU = torch.linalg.solve(phi,A)\n",
    "    except:\n",
    "        A = A.detach().numpy()\n",
    "        phi2 = phi.detach().numpy()\n",
    "        tmp = torch.Tensor(np.linalg.solve(A, phi2))\n",
    "\n",
    "    return torch.sqrt(torch.matmul(torch.transpose(phi,1,0), tmp))\n",
    "\n",
    "def calculate_v(contextinfo_list, A, theta):\n",
    "    vj_list = []\n",
    "    feature_list = []\n",
    "    for i in contextinfo_list:\n",
    "        feature = model(i.to(device)).cpu()\n",
    "        first_item =  torch.mm( feature.view(1,-1) , theta)\n",
    "        second_item = alpha * UCB(A, feature)\n",
    "        vj_list.append((first_item + second_item).item())\n",
    "        feature_list.append(feature.detach().numpy())\n",
    "    return np.array(vj_list), feature_list\n",
    "\n",
    "def update_A(A, info_subset):\n",
    "    for i in info_subset:\n",
    "        i = torch.tensor(i, dtype=torch.float32,device=device)\n",
    "        feature = model(i.to(device)).view(1,-1).cpu()\n",
    "        A = A + torch.mm(feature.t(), feature)\n",
    "    return A\n",
    "\n",
    "def prob(vj_list):\n",
    "    sum = np.sum(np.exp(vj_list)) + 1\n",
    "    return [np.exp(vj_list[i]) / sum for i in range(len(vj_list))]  \n",
    "\n",
    "def revenue(vj_list, reward_list):\n",
    "    sum = np.sum(np.exp(vj_list)) + 1\n",
    "    return np.sum(np.multiply(np.exp(vj_list), reward_list) / sum)\n",
    "\n",
    "def assort(contextinfo_list, reward_list, vj_list):\n",
    "    length = len(vj_list)\n",
    "    # sort the contextinfo_list and vj with descending order of reward_list\n",
    "    sorted_list = sorted(zip(contextinfo_list, vj_list, reward_list), key=lambda x: x[2], reverse=True)\n",
    "    contextinfo_list = [x[0] for x in sorted_list]\n",
    "    vj_list = [x[1] for x in sorted_list]\n",
    "    reward_list = [x[2] for x in sorted_list]\n",
    "\n",
    "    # calculate the optimal assortment\n",
    "    optimal_assort = []\n",
    "    optimal_reward = 0\n",
    "    index = 1\n",
    "    for i in range(length):\n",
    "        if revenue(vj_list[:index], reward_list[:index]) >= optimal_reward:\n",
    "            optimal_reward = revenue(vj_list[:index], reward_list[:index])\n",
    "            index += 1\n",
    "        else:\n",
    "            break\n",
    "    return contextinfo_list[:index]\n",
    "\n",
    "# this is for the linear purchase model when v = x dot theta\n",
    "def get_linear_purchase(feature_list):\n",
    "    true_Vlist = [(TRUE_THETA @ feature_list[i].reshape(-1,1)).item() for  i in range(len(feature_list))]\n",
    "    prob_list = prob(true_Vlist)\n",
    "\n",
    "    # sample item according to prob_list\n",
    "    if random.uniform(0,1) < 1 - np.sum(prob_list):\n",
    "        return np.array([0 for i in range(len(feature_list))])\n",
    "    else:\n",
    "        returnlist = [0 for i in range(len(feature_list))]\n",
    "        indexchoose = random.choices([i for i in range(len(prob_list))], weights = prob_list)[0]\n",
    "        returnlist[indexchoose] = 1\n",
    "        return np.array(returnlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(theta, feature_list,y_list):\n",
    "    # feature's dimension is len * dimension , theta is 1*dimension\n",
    "    v_list = np.matmul(feature_list, theta.T).reshape(-1)\n",
    "    ln_prob = np.log(prob(v_list))\n",
    "    summation = ln_prob * y_list\n",
    "    return -1 * np.sum(ln_prob)\n",
    "\n",
    "def likelihood_derivative(theta, feature_list, y_list):\n",
    "    v_list = np.matmul(feature_list, theta.T).reshape(-1)\n",
    "    prob_list = prob(v_list)\n",
    "    summation = np.matmul(np.array(feature_list).T, (y_list - prob_list))\n",
    "    return -1 * summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\gitproject\\Neural_bandit\\neural_ass\\asstest.ipynb Cell 4\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/gitproject/Neural_bandit/neural_ass/asstest.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimize\u001b[39;00m \u001b[39mimport\u001b[39;00m minimize\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/gitproject/Neural_bandit/neural_ass/asstest.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m initial_guess \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m0.5\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m15\u001b[39m)])  \n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/gitproject/Neural_bandit/neural_ass/asstest.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m known_feature \u001b[39m=\u001b[39m a\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/gitproject/Neural_bandit/neural_ass/asstest.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m known_y \u001b[39m=\u001b[39m  y\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/gitproject/Neural_bandit/neural_ass/asstest.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m result \u001b[39m=\u001b[39m minimize(likelihood, initial_guess, args\u001b[39m=\u001b[39m(known_feature, known_y), method\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSLSQP\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/gitproject/Neural_bandit/neural_ass/asstest.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                   constraints\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39meq\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfun\u001b[39m\u001b[39m'\u001b[39m: likelihood_derivative, \u001b[39m'\u001b[39m\u001b[39margs\u001b[39m\u001b[39m'\u001b[39m:(known_feature, known_y)})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "initial_guess = np.array([0.5 for i in range(15)])  \n",
    "\n",
    "known_feature = a\n",
    "known_y =  y\n",
    "\n",
    "result = minimize(likelihood, initial_guess, args=(known_feature, known_y), method='SLSQP', \n",
    "                  constraints={'type':'eq', 'fun': likelihood_derivative, 'args':(known_feature, known_y)})\n",
    "\n",
    "optimal_parameters = result.x\n",
    "print(\"最优参数:\", optimal_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLikelihoodLoss(nn.Module):\n",
    "    def __init__(self, theta):\n",
    "        super(CustomLikelihoodLoss, self).__init__()\n",
    "        self.theta = theta\n",
    "        \n",
    "    def forward(self, output_list, y_list):\n",
    "        loss = 0\n",
    "        index = 0\n",
    "        for output in output_list:  \n",
    "            y = torch.tensor(y_list[index]).to(device)\n",
    "            v = torch.mm(output, self.theta.view(-1,1))\n",
    "            prob = torch.exp(v) / (torch.sum(torch.exp(v)) + 1)\n",
    "            loss += torch.sum(torch.log(prob) * y)\n",
    "            index += 1  \n",
    "        return -loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a test set \n",
    "a = torch.randn(100,10).numpy()\n",
    "theta  = np.random.randint(1,4,(1,10)).reshape(-1)\n",
    "y = np.array([1] + [0 for i in range(99)])\n",
    "y = np.random.permutation(y)\n",
    "\n",
    "a_list = []\n",
    "y_list = []\n",
    "for i in [20,30,50,100, 60, 80]:\n",
    "    a = torch.randn(i,10).numpy()\n",
    "    a_list.append(a)\n",
    "    y = np.array([1] + [0 for i in range(i-1)]) \n",
    "    y = np.random.permutation(y)\n",
    "    y_list.append(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5, 10, 10, 10, 10, 10, 10], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import modeldefine\n",
    "import torch.optim as optim\n",
    "model = modeldefine.Model(5,10,10,5).to(device)\n",
    "# 10 20 20 20 20 20  5\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 2288.6337890625\n",
      "Epoch [2/10], Loss: 1637.2301025390625\n",
      "Epoch [3/10], Loss: 1473.3623046875\n",
      "Epoch [4/10], Loss: 1453.34814453125\n",
      "Epoch [5/10], Loss: 1440.3856201171875\n",
      "Epoch [6/10], Loss: 1431.3837890625\n",
      "Epoch [7/10], Loss: 1426.150146484375\n",
      "Epoch [8/10], Loss: 1421.9503173828125\n",
      "Epoch [9/10], Loss: 1418.9248046875\n",
      "Epoch [10/10], Loss: 1417.478271484375\n"
     ]
    }
   ],
   "source": [
    "loss_function = CustomLikelihoodLoss(torch.Tensor(theta).to(device))\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    output_list = [model(torch.tensor(a).to(device)) for a in a_list]\n",
    "    loss = loss_function(output_list, y_list)\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}\")\n",
    "      \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_ARRAY = np.load('linear_data/features.npy') \n",
    "REWARD_ARRAY = np.load('linear_data/rewards.npy')\n",
    "TRUE_THETA = np.load('linear_data/theta.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = len(CONTEXT_ARRAY)\n",
    "\n",
    "# define the hyperparameters\n",
    "input_size = 20\n",
    "hidden_size = 20\n",
    "output_size = 10\n",
    "num_layers = 10\n",
    "\n",
    "beta = 0.1\n",
    "lambd = 1\n",
    "H = 100\n",
    "\n",
    "# initialize the parameters\n",
    "\n",
    "theta = np.random.randn(output_size, 1) / np.sqrt(output_size)\n",
    "theta = torch.tensor(theta, dtype=torch.float32)\n",
    "LAMBDA = lambd * torch.eye(output_size, dtype=torch.float32)\n",
    "\n",
    "for t in range(0,10000):\n",
    "    context = CONTEXT_ARRAY[t]\n",
    "    profit = REWARD_ARRAY[t]\n",
    "    v_array = calculate_v(torch.tensor(context,dtype=torch.float32), LAMBDA, theta)[0]\n",
    "    assortment = assort(context, profit.tolist()[0], v_array.tolist() )\n",
    "    purchase_vector = get_linear_purchase(assortment)\n",
    "\n",
    "    # update the parameters\n",
    "    LAMBDA = update_A(LAMBDA, assortment)\n",
    "    \n",
    "    # update theta using MLE\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = CONTEXT_ARRAY[1]\n",
    "profit = REWARD_ARRAY[1]\n",
    "\n",
    "v_array = calculate_v(torch.tensor(context,dtype=torch.float32), LAMBDA, theta)[0]\n",
    "ass = assort(context, profit.tolist()[0], v_array.tolist() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bandit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
