{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import math \n",
    "import copy\n",
    "import random\n",
    "import argparse\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import modeldefine\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "\n",
    "def UCB(A, phi):\n",
    "    #### ucb term\n",
    "    phi = phi.view(-1,1)\n",
    "    try:\n",
    "        tmp, LU = torch.linalg.solve(phi,A)\n",
    "    except:\n",
    "        A = A.detach().numpy()\n",
    "        phi2 = phi.detach().numpy()\n",
    "        tmp = torch.Tensor(np.linalg.solve(A, phi2))\n",
    "\n",
    "    return torch.sqrt(torch.matmul(torch.transpose(phi,1,0), tmp))\n",
    "\n",
    "def calculate_v(contextinfo_list, A, theta):\n",
    "    vj_list = []\n",
    "    feature_list = []\n",
    "    for i in contextinfo_list:\n",
    "        feature = model(i.to(device)).cpu()\n",
    "        first_item =  torch.mm( feature.view(1,-1) , theta)\n",
    "        second_item = alpha * UCB(A, feature)\n",
    "        vj_list.append((first_item + second_item).item())\n",
    "        feature_list.append(feature.detach().numpy())\n",
    "    return np.array(vj_list), feature_list\n",
    "\n",
    "def update_A(A, info_subset):\n",
    "    for i in info_subset:\n",
    "        i = torch.tensor(i, dtype=torch.float32,device=device)\n",
    "        feature = model(i.to(device)).view(1,-1).cpu()\n",
    "        A = A + torch.mm(feature.t(), feature)\n",
    "    return A\n",
    "\n",
    "def prob(vj_list):\n",
    "    sum = np.sum(np.exp(vj_list)) + 1\n",
    "    return [np.exp(vj_list[i]) / sum for i in range(len(vj_list))]  \n",
    "\n",
    "def revenue(vj_list, reward_list):\n",
    "    sum = np.sum(np.exp(vj_list)) + 1\n",
    "    return np.sum(np.multiply(np.exp(vj_list), reward_list) / sum)\n",
    "\n",
    "def assort(contextinfo_list, reward_list, vj_list, feature_list):\n",
    "    length = len(vj_list)\n",
    "    # sort the contextinfo_list and vj with descending order of reward_list\n",
    "    sorted_list = sorted(zip(contextinfo_list, vj_list, reward_list, feature_list), key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    contextinfo_list = [x[0] for x in sorted_list]\n",
    "    vj_list = [x[1] for x in sorted_list]\n",
    "    reward_list = [x[2] for x in sorted_list]\n",
    "    feature_list = [x[3] for x in sorted_list]\n",
    "\n",
    "    # calculate the optimal assortment\n",
    "    optimal_assort = []\n",
    "    optimal_reward = 0\n",
    "    index = 1\n",
    "    for i in range(length):\n",
    "        if revenue(vj_list[:index], reward_list[:index]) >= optimal_reward:\n",
    "            optimal_reward = revenue(vj_list[:index], reward_list[:index])\n",
    "            index += 1\n",
    "        else:\n",
    "            break\n",
    "    return contextinfo_list[:index], feature_list[:index]\n",
    "\n",
    "# this is for the linear purchase model when v = x dot theta\n",
    "def get_linear_purchase(feature_list):\n",
    "    true_Vlist = [(TRUE_THETA @ feature_list[i].reshape(-1,1)).item() for  i in range(len(feature_list))]\n",
    "    prob_list = prob(true_Vlist)\n",
    "\n",
    "    # sample item according to prob_list\n",
    "    if random.uniform(0,1) < 1 - np.sum(prob_list):\n",
    "        return np.array([0 for i in range(len(feature_list))])\n",
    "    else:\n",
    "        returnlist = [0 for i in range(len(feature_list))]\n",
    "        indexchoose = random.choices([i for i in range(len(prob_list))], weights = prob_list)[0]\n",
    "        returnlist[indexchoose] = 1\n",
    "        return np.array(returnlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambd = 1\n",
    "def likelihood(theta, feature_list ,y_list):\n",
    "    # feature's dimension is len * dimension , theta is 1*dimension\n",
    "    v_list = np.matmul(feature_list, theta.T).reshape(-1)\n",
    "    ln_prob = np.log(prob(v_list))\n",
    "    summation = ln_prob * y_list\n",
    "    return -1 * np.sum(summation)\n",
    "\n",
    "def likelihood_derivative(theta, feature_list, y_list):\n",
    "    v_list = np.matmul(feature_list, theta.T).reshape(-1)\n",
    "    prob_list = prob(v_list)\n",
    "    summation = np.matmul(np.array(feature_list).T, (y_list - prob_list))\n",
    "    return -1 * summation\n",
    "\n",
    "def likelihood_array(theta, feature_list_list, y_list_list):\n",
    "    summation =  0.5 * lambd * np.dot(theta, theta)\n",
    "    for i in range(len(feature_list_list)):\n",
    "        summation += likelihood(theta, feature_list_list[i], y_list_list[i])\n",
    "    return summation\n",
    "\n",
    "def likelihood_derivative_array(theta, feature_list_list, y_list_list):\n",
    "    summation = 0.5 * lambd * theta\n",
    "    for i in range(len(feature_list_list)):\n",
    "        summation += likelihood_derivative(theta, feature_list_list[i], y_list_list[i])\n",
    "    return summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLikelihoodLoss(nn.Module): \n",
    "    def __init__(self, theta_list):\n",
    "        super(CustomLikelihoodLoss, self).__init__()\n",
    "        self.theta_list = theta_list\n",
    "\n",
    "    def forward(self, output_list, y_list):\n",
    "        loss = 0\n",
    "        index = 0\n",
    "        for output in output_list:  \n",
    "            y = torch.tensor(y_list[index]).to(device) \n",
    "            theta = torch.tensor(self.theta_list[index], dtype= torch.float32).to(device) \n",
    "            v = torch.mm(output, theta.view(-1,1)) \n",
    "            prob = torch.exp(v) / (torch.sum(torch.exp(v)) + 1)  \n",
    "            loss += torch.sum(torch.log(prob) * y)  \n",
    "            index += 1  \n",
    "        return -loss \n",
    "\n",
    "class CustomLikelihoodLoss2(nn.Module):\n",
    "    def __init__(self, theta_list):\n",
    "        super(CustomLikelihoodLoss2, self).__init__()\n",
    "        self.theta_list = theta_list\n",
    "     \n",
    "    def forward(self, output_list, y_list):\n",
    "        loss = 0\n",
    "        index = 0\n",
    "        for output in output_list:\n",
    "            y = torch.tensor(y_list[index]).to(device)\n",
    "            theta = torch.tensor(self.theta_list[index], dtype= torch.float32).to(device)\n",
    "            v = torch.mm(output, theta.view(-1,1))\n",
    "            prob = torch.exp(v) / (torch.sum(torch.exp(v)) + 1)\n",
    "            # ce loss between prob and y\n",
    "            loss += torch.sum(-y * torch.log(prob) - (1-y) * torch.log(1-prob))\n",
    "            index += 1\n",
    "        return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5, 10, 10, 10], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import modeldefine\n",
    "import torch.optim as optim\n",
    "model = modeldefine.Model(5,10,10,2).to(device)\n",
    "# 10 20 20 20 20 20  5\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001,weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_ARRAY = np.load('linear_data/features.npy') \n",
    "REWARD_ARRAY = np.load('linear_data/rewards.npy')\n",
    "TRUE_THETA = np.load('linear_data/theta.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Loss: 1523.2236328125\n",
      "Epoch [1/1], Loss: 871.5902709960938\n",
      "Epoch [1/1], Loss: 923.3260498046875\n",
      "Epoch [1/1], Loss: 863.8228149414062\n",
      "Epoch [1/1], Loss: 810.2725219726562\n"
     ]
    }
   ],
   "source": [
    "data_length = len(CONTEXT_ARRAY)\n",
    "\n",
    "# define the hyperparameters\n",
    "input_size = 20\n",
    "hidden_size = 20\n",
    "output_size = 10\n",
    "num_layers = 10\n",
    "\n",
    "beta = 0.1\n",
    "\n",
    "H = 100\n",
    "\n",
    "# initialize the parameters\n",
    "\n",
    "theta = np.random.randn(output_size) / np.sqrt(output_size)\n",
    "\n",
    "LAMBDA = lambd * torch.eye(output_size, dtype=torch.float32)\n",
    "\n",
    "\n",
    "ass_list = []\n",
    "feature_list = []\n",
    "purchase_list = []\n",
    "theta_list = []\n",
    "for t in range(0,500):\n",
    "    context = CONTEXT_ARRAY[t]\n",
    "    profit = REWARD_ARRAY[t]\n",
    "\n",
    "    theta_tensor = torch.tensor(theta.reshape(-1,1), dtype=torch.float32)\n",
    "    v_array,initial_feature = calculate_v(torch.tensor(context,dtype=torch.float32), LAMBDA, theta_tensor)\n",
    "    assortment, ass_features = assort(context, profit.tolist()[0], v_array.tolist() , initial_feature)\n",
    "    \n",
    "    purchase_vector = get_linear_purchase(assortment)\n",
    "\n",
    "    # add to list\n",
    "    ass_list.append(np.array(assortment))\n",
    "    feature_list.append(np.array(ass_features))\n",
    "    purchase_list.append(purchase_vector)\n",
    "    # update the parameters\n",
    "    LAMBDA = update_A(LAMBDA, assortment)\n",
    "    \n",
    "    # update theta using MLE\n",
    "    \n",
    "    initial_guess = theta\n",
    "    result = minimize(likelihood_array, initial_guess, args=(ass_list, purchase_list), method='SLSQP', \n",
    "                  constraints={'type':'eq', 'fun': likelihood_derivative_array, 'args':(ass_list, purchase_list)})\n",
    "    theta = result.x\n",
    "    #print(\"best parameter\",theta)\n",
    "    theta_list.append(theta)\n",
    "\n",
    "    # update the neural networks\n",
    "\n",
    "    if t % H == 99:\n",
    "        a_list = ass_list[-1*H:]\n",
    "        y_list = purchase_list[-1*H:]\n",
    "\n",
    "        loss_function = CustomLikelihoodLoss2(theta_list)\n",
    "        epochs = 1\n",
    "     \n",
    "        for epoch in range(epochs):\n",
    "            output_list = [model(torch.tensor(a,dtype = torch.float32).to(device)) for a in a_list]\n",
    "            loss = loss_function(output_list, y_list)\n",
    "            if (epoch == epochs-1): print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}\")\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        theta_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ass_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.10034455, 0.21076841, 0.14508133, 0.17142846, 0.35271862])]\n",
      "[0.1751723105153316, 0.19349765871217414, 0.19444030831360465, 0.19445180548264548, 0.2031202921112658]\n"
     ]
    }
   ],
   "source": [
    "print(prob((ass_list[99] @ TRUE_THETA.reshape(10,1)).reshape(1,-1)))\n",
    "print(prob(calculate_v(torch.tensor(ass_list[99],dtype=torch.float32), LAMBDA, theta_tensor)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.15502461, 0.32562099, 0.22413951, 0.26484381])]\n",
      "[0.24075096504913812, 0.3043562395370432, 0.23672812938242793, 0.20178608293386321]\n"
     ]
    }
   ],
   "source": [
    "print(prob((ass_list[99] @ TRUE_THETA.reshape(10,1)).reshape(1,-1)))\n",
    "print(prob(calculate_v(torch.tensor(ass_list[99],dtype=torch.float32), LAMBDA, theta_tensor)[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchase_list[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.93355882, 1.94060946])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_v(torch.tensor(ass_list[3],dtype=torch.float32), LAMBDA, theta_tensor)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'testmodel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('testtheta.npy',theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bandit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
