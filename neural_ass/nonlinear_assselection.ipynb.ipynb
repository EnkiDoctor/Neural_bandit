{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import math \n",
    "import copy\n",
    "import random\n",
    "import argparse\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import modeldefine\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "\n",
    "def UCB(A, phi):\n",
    "    #### ucb term\n",
    "    phi = phi.view(-1,1)\n",
    "    try:\n",
    "        tmp, LU = torch.linalg.solve(phi,A)\n",
    "    except:\n",
    "        A = A.detach().numpy()\n",
    "        phi2 = phi.detach().numpy()\n",
    "        tmp = torch.Tensor(np.linalg.solve(A, phi2))\n",
    "\n",
    "    return torch.sqrt(torch.matmul(torch.transpose(phi,1,0), tmp))\n",
    "\n",
    "def calculate_v(contextinfo_list, A, theta):\n",
    "    vj_list = []\n",
    "    feature_list = []\n",
    "    for i in contextinfo_list:\n",
    "        feature = model(i.to(device)).cpu()\n",
    "        first_item =  torch.mm( feature.view(1,-1) , theta)\n",
    "        second_item = alpha * UCB(A, feature)\n",
    "        vj_list.append((first_item + second_item).item())\n",
    "        feature_list.append(feature.detach().numpy())\n",
    "    return np.array(vj_list), feature_list\n",
    "\n",
    "def update_A(A, info_subset):\n",
    "    for i in info_subset:\n",
    "        i = torch.tensor(i, dtype=torch.float32,device=device)\n",
    "        feature = model(i.to(device)).view(1,-1).cpu()\n",
    "        A = A + torch.mm(feature.t(), feature)\n",
    "    return A\n",
    "\n",
    "# 这里调小utility \n",
    "def prob(vj_list):\n",
    "    sum = np.sum(np.exp(vj_list)) + 1\n",
    "    return [np.exp(vj_list[i]) / sum for i in range(len(vj_list))]  \n",
    "\n",
    "def revenue(vj_list, reward_list):\n",
    "    sum = np.sum(np.exp(vj_list)) + 1\n",
    "    return np.sum(np.multiply(np.exp(vj_list), reward_list) / sum)\n",
    "\n",
    "def assort(contextinfo_list, reward_list, vj_list, feature_list):\n",
    "    length = len(vj_list)\n",
    "    # sort the contextinfo_list and vj with descending order of reward_list\n",
    "    sorted_list = sorted(zip(contextinfo_list, vj_list, reward_list, feature_list), key=lambda x: x[2], reverse=True)\n",
    "    \n",
    "    contextinfo_list = [x[0] for x in sorted_list]\n",
    "    vj_list = [x[1] for x in sorted_list]\n",
    "    reward_list = [x[2] for x in sorted_list]\n",
    "    feature_list = [x[3] for x in sorted_list]\n",
    "\n",
    "    # calculate the optimal assortment\n",
    "    optimal_assort = []\n",
    "    optimal_reward = 0\n",
    "    index = 1\n",
    "    for i in range(length):\n",
    "        if revenue(vj_list[:index], reward_list[:index]) >= optimal_reward:\n",
    "            optimal_reward = revenue(vj_list[:index], reward_list[:index])\n",
    "            index += 1\n",
    "        else:\n",
    "            break\n",
    "    return contextinfo_list[:index], feature_list[:index], vj_list[:index], reward_list[:index]\n",
    "\n",
    "# this is for the linear purchase model when v = x dot theta\n",
    "def get_linear_purchase(feature_list):\n",
    "    true_Vlist = [(TRUE_THETA @ feature_list[i].reshape(-1,1)).item() for  i in range(len(feature_list))]\n",
    "    prob_list = prob(true_Vlist)\n",
    "\n",
    "    # sample item according to prob_list\n",
    "    if random.uniform(0,1) < 1 - np.sum(prob_list):\n",
    "        return np.array([0 for i in range(len(feature_list))])\n",
    "    else:\n",
    "        returnlist = [0 for i in range(len(feature_list))]\n",
    "        indexchoose = random.choices([i for i in range(len(prob_list))], weights = prob_list)[0]\n",
    "        returnlist[indexchoose] = 1\n",
    "        return np.array(returnlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambd = 1\n",
    "def likelihood(theta, feature_list ,y_list):\n",
    "    # feature's dimension is len * dimension , theta is 1*dimension\n",
    "    v_list = np.matmul(feature_list, theta.T).reshape(-1)\n",
    "    ln_prob = np.log(prob(v_list))\n",
    "    summation = ln_prob * y_list\n",
    "    return -1 * np.sum(summation)\n",
    "\n",
    "def likelihood_derivative(theta, feature_list, y_list):\n",
    "    v_list = np.matmul(feature_list, theta.T).reshape(-1)\n",
    "    prob_list = prob(v_list)\n",
    "    summation = np.matmul(np.array(feature_list).T, (y_list - prob_list))\n",
    "    return -1 * summation\n",
    "\n",
    "def likelihood_array(theta, feature_list_list, y_list_list):\n",
    "    summation =  0.5 * lambd * np.dot(theta, theta)\n",
    "    for i in range(len(feature_list_list)):\n",
    "        summation += likelihood(theta, feature_list_list[i], y_list_list[i])\n",
    "    return summation\n",
    "\n",
    "def likelihood_derivative_array(theta, feature_list_list, y_list_list):\n",
    "    summation = 0.5 * lambd * theta\n",
    "    for i in range(len(feature_list_list)):\n",
    "        summation += likelihood_derivative(theta, feature_list_list[i], y_list_list[i])\n",
    "    return summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLikelihoodLoss(nn.Module): \n",
    "    def __init__(self, theta_list):\n",
    "        super(CustomLikelihoodLoss, self).__init__()\n",
    "        self.theta_list = theta_list\n",
    "\n",
    "    def forward(self, output_list, y_list):\n",
    "        loss = 0\n",
    "        index = 0\n",
    "        for output in output_list:  \n",
    "            y = torch.tensor(y_list[index]).to(device) .view(-1,1)\n",
    "            theta = torch.tensor(self.theta_list[index], dtype= torch.float32).to(device) \n",
    "            v = torch.mm(output, theta.view(-1,1)) \n",
    "            prob = torch.exp(v) / (torch.sum(torch.exp(v)) + 1)  \n",
    "            loss += torch.sum(torch.log(prob) * y)  \n",
    "            index += 1  \n",
    "        return -loss \n",
    "\n",
    "class CustomLikelihoodLoss2(nn.Module):\n",
    "    def __init__(self, theta_list):\n",
    "        super(CustomLikelihoodLoss2, self).__init__()\n",
    "        self.theta_list = theta_list\n",
    "     \n",
    "    def forward(self, output_list, y_list):\n",
    "        loss = 0\n",
    "        index = 0\n",
    "        for output in output_list:\n",
    "            y = torch.tensor(y_list[index]).to(device).view(-1,1)\n",
    "            theta = torch.tensor(self.theta_list[index], dtype= torch.float32).to(device)\n",
    "            v = torch.mm(output, theta.view(-1,1))\n",
    "            prob = torch.exp(v) / (torch.sum(torch.exp(v)) + 1)\n",
    "            # ce loss between prob and y\n",
    "            loss += torch.sum(-y * torch.log(prob) - (1-y) * torch.log(1-prob))\n",
    "            index += 1\n",
    "        return loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this block is only used for linear model revenue calculation\n",
    "def calculate_linear_v(contextinfo_list, A, theta):\n",
    "    vj_list = []\n",
    "    feature_list = []\n",
    "    for i in contextinfo_list:\n",
    "        feature = i\n",
    "        first_item =  torch.mm( feature.view(1,-1) , theta)\n",
    "\n",
    "        vj_list.append(first_item.item())\n",
    "        feature_list.append(feature.detach().numpy())\n",
    "    return np.array(vj_list), feature_list\n",
    "\n",
    "# 真实情况乱下的theta，feature\n",
    "def get_true_linear_ass(context, profit):\n",
    "    theta_tensor = torch.tensor(TRUE_THETA.reshape(-1,1), dtype=torch.float32)\n",
    "    v_array,initial_feature = calculate_linear_v(torch.tensor(context,dtype=torch.float32), LAMBDA, theta_tensor)\n",
    "    assortment, ass_features, v_list, profit_list = assort(context, profit.tolist()[0], v_array.tolist() , initial_feature)\n",
    "    true_probablility = np.array(prob(v_list))\n",
    "    revenue = np.dot(true_probablility, np.array(profit_list))\n",
    "    return revenue\n",
    "\n",
    "\n",
    "def get_assortment_revenue(assortment, profit):\n",
    "    theta_tensor = torch.tensor(TRUE_THETA.reshape(-1,1), dtype=torch.float32)\n",
    "    v_array,initial_feature = calculate_linear_v(torch.tensor(assortment,dtype=torch.float32), LAMBDA, theta_tensor)\n",
    "    true_probablility = np.array(prob(v_array))\n",
    "    revenue = np.dot(true_probablility, np.array(profit))\n",
    "    return revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5, 10, 10, 10], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import modeldefine\n",
    "import torch.optim as optim\n",
    "model = modeldefine.Model(5,10,10,2).to(device)\n",
    "# 10 20 20 20 20 20  5\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01,weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data reader\n",
    "CONTEXT_ARRAY = np.load('linear_data/features.npy') \n",
    "REWARD_ARRAY = np.load('linear_data/rewards.npy')\n",
    "TRUE_THETA = np.load('linear_data/theta.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alienware\\AppData\\Local\\Temp\\ipykernel_10216\\2392795184.py:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  v_array,initial_feature = calculate_linear_v(torch.tensor(assortment,dtype=torch.float32), LAMBDA, theta_tensor)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Loss: 284.0516662597656\n",
      "Epoch [1/1], Loss: 242.5410614013672\n",
      "Epoch [1/1], Loss: 225.7886962890625\n",
      "Epoch [1/1], Loss: 207.48240661621094\n",
      "Epoch [1/1], Loss: 199.094482421875\n",
      "Epoch [1/1], Loss: 187.4322509765625\n",
      "Epoch [1/1], Loss: 195.0421142578125\n",
      "Epoch [1/1], Loss: 183.36216735839844\n",
      "Epoch [1/1], Loss: 184.12957763671875\n",
      "Epoch [1/1], Loss: 181.85052490234375\n"
     ]
    }
   ],
   "source": [
    "data_length = len(CONTEXT_ARRAY)\n",
    "\n",
    "# define the hyperparameters\n",
    "input_size = 20\n",
    "hidden_size = 20\n",
    "output_size = 10\n",
    "num_layers = 10\n",
    "\n",
    "beta = 0.1\n",
    "\n",
    "H = 100\n",
    "\n",
    "# initialize the parameters\n",
    "\n",
    "theta = np.random.randn(output_size) / np.sqrt(output_size)\n",
    "\n",
    "LAMBDA = lambd * torch.eye(output_size, dtype=torch.float32)\n",
    "\n",
    "ass_list = []\n",
    "feature_list = []\n",
    "purchase_list = []\n",
    "theta_list = []\n",
    "\n",
    "revenue_list1 = []\n",
    "revenue_list2 = []\n",
    "true_profit_list = []\n",
    "\n",
    "for t in range(0,1000):\n",
    "    context = CONTEXT_ARRAY[t]\n",
    "    profit = REWARD_ARRAY[t]\n",
    "\n",
    "    theta_tensor = torch.tensor(theta.reshape(-1,1), dtype=torch.float32)\n",
    "    v_array,initial_feature = calculate_v(torch.tensor(context,dtype=torch.float32), LAMBDA, theta_tensor)\n",
    "    assortment, ass_features, vv_list , reward = assort(context, profit.tolist()[0], v_array.tolist() , initial_feature)\n",
    "    purchase_vector = get_linear_purchase(assortment)\n",
    "    \n",
    "    # calculate the ideal \n",
    "    expected_revenue1 = get_true_linear_ass(context, profit)\n",
    "    revenue_list1.append(expected_revenue1)\n",
    "    true_profit_list.append(np.dot(np.array(purchase_vector), reward))\n",
    "    revenue_list2.append(get_assortment_revenue(assortment, reward))\n",
    "\n",
    "    # add to list\n",
    "    ass_list.append(np.array(assortment))\n",
    "    feature_list.append(np.array(ass_features))\n",
    "    purchase_list.append(purchase_vector)\n",
    "\n",
    "    # update the parameters\n",
    "    LAMBDA = update_A(LAMBDA, assortment)\n",
    "    \n",
    "    # update theta using MLE\n",
    "    initial_guess = theta\n",
    "    result = minimize(likelihood_array, initial_guess, args=(ass_list, purchase_list), method='SLSQP', \n",
    "                  constraints={'type':'eq', 'fun': likelihood_derivative_array, 'args':(ass_list, purchase_list)})\n",
    "    theta = result.x\n",
    "    theta_list.append(theta)\n",
    "\n",
    "    # update the neural networks\n",
    "    if t % H == 99:\n",
    "        a_list = ass_list[-1*H:]\n",
    "        y_list = purchase_list[-1*H:]\n",
    "\n",
    "        loss_function = CustomLikelihoodLoss2(theta_list)\n",
    "        epochs = 1\n",
    "     \n",
    "        for epoch in range(epochs):\n",
    "            output_list = [model(torch.tensor(a,dtype = torch.float32).to(device)) for a in a_list]\n",
    "            loss = loss_function(output_list, y_list)\n",
    "            if (epoch == epochs-1): print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}\")\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        theta_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('linear_data/record/true_revenue_list1.npy', np.array(revenue_list1))\n",
    "np.save('linear_data/record/simulate_revenue_list2.npy', np.array(revenue_list2))\n",
    "np.save('linear_data/record/purchase_revenue_list.npy', np.array(true_profit_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.24755697, 0.17920725, 0.10858287, 0.22995762, 0.22108807])]\n",
      "[0.23925270797584142, 0.20596848007044882, 0.08502806381887187, 0.23441803513736983, 0.2289798856667121]\n"
     ]
    }
   ],
   "source": [
    "print(prob((ass_list[100] @ TRUE_THETA.reshape(10,1)).reshape(1,-1)))\n",
    "print(prob(calculate_v(torch.tensor(ass_list[100],dtype=torch.float32), LAMBDA, theta_tensor)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.10034455, 0.21076841, 0.14508133, 0.17142846, 0.35271862])]\n",
      "[0.09658509735433717, 0.18352291563725892, 0.12234222012826149, 0.16023457541176545, 0.42805959006122735]\n"
     ]
    }
   ],
   "source": [
    "print(prob((ass_list[99] @ TRUE_THETA.reshape(10,1)).reshape(1,-1)))\n",
    "print(prob(calculate_v(torch.tensor(ass_list[99],dtype=torch.float32), LAMBDA, theta_tensor)[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchase_list[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regret calculate\n",
    "# ult - 1  让不购买概率最大\n",
    "# matolotlib linear  10000 epoch \n",
    "# 真实情况下的expected revenue， theta， Truetheta\n",
    "# expected 和 assortment 的revenue 顾客的purchase \n",
    "# \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bandit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
